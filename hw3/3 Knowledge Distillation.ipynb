{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3 Knowledge Distillation.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "u3vhv5zl-p7z",
    "P0osHIcMCbFu"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3e8d78e11edd4bb7a1d9c54ac7ca5d3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_e536fad866fb4c7ea4f7cd088da1fa3b",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_1266283a54df4266a64f498e518c17d3",
       "IPY_MODEL_f062005aed5448359d3dedd1f11f5f2e"
      ]
     }
    },
    "e536fad866fb4c7ea4f7cd088da1fa3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "1266283a54df4266a64f498e518c17d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_98a9522709894f769205f07491ea6ab1",
      "_dom_classes": [],
      "description": "Epoch: 0 Loss: 2.091: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3fe45f951a1f4457aef8d9ad59f37bb6"
     }
    },
    "f062005aed5448359d3dedd1f11f5f2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a7357f9832674730be4ebae17880e9ce",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [10:21&lt;00:00,  2.98it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_74ca3486b014477281a7b7f324cc2023"
     }
    },
    "98a9522709894f769205f07491ea6ab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3fe45f951a1f4457aef8d9ad59f37bb6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a7357f9832674730be4ebae17880e9ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "74ca3486b014477281a7b7f324cc2023": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "480d6e368ef64f0685a02ff1c2d3bcb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_6c4f3dc4e9554ad6b03ada65704c8460",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_df64a0a5d79546858d5e1b2523c1f785",
       "IPY_MODEL_202b1639588740fcaf57e6813e9dcc01"
      ]
     }
    },
    "6c4f3dc4e9554ad6b03ada65704c8460": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "df64a0a5d79546858d5e1b2523c1f785": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_8547184ee853490c8841e6a9aa05981d",
      "_dom_classes": [],
      "description": "Epoch: 1 Loss: 2.006: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_37f0f106849e4c5fa0a0ffc6c7517f16"
     }
    },
    "202b1639588740fcaf57e6813e9dcc01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_5452b9600ebf4a6fa7236a22fa2057d0",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [10:21&lt;00:00,  2.98it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_9047cb0463384e028c8588a67ed61d3d"
     }
    },
    "8547184ee853490c8841e6a9aa05981d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "37f0f106849e4c5fa0a0ffc6c7517f16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5452b9600ebf4a6fa7236a22fa2057d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "9047cb0463384e028c8588a67ed61d3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "39e76015f3074852b2b9b770a23d1766": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_0401cb9c17e242289c6c834971c5e9ce",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_21fed3174f87442aa15bb1848f7495a7",
       "IPY_MODEL_8bad6eafc2b94d49886a931d7da07497"
      ]
     }
    },
    "0401cb9c17e242289c6c834971c5e9ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "21fed3174f87442aa15bb1848f7495a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_4f8f3be4b6db48af989b8d3b7b787f53",
      "_dom_classes": [],
      "description": "Epoch: 2 Loss: 1.98: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6114a59730174ebebdb51ab6f238bcc5"
     }
    },
    "8bad6eafc2b94d49886a931d7da07497": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_62ce9c634911447d8b56d1f6e3cea069",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [15:24&lt;00:00,  2.01it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_14ae9113d91f46b59f1308718f2df0a6"
     }
    },
    "4f8f3be4b6db48af989b8d3b7b787f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "6114a59730174ebebdb51ab6f238bcc5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "62ce9c634911447d8b56d1f6e3cea069": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "14ae9113d91f46b59f1308718f2df0a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "733730ba3556461fb39ea30db3a5542c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_08cb7a9bfc2940abb91f5dcc6677d384",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_27d8cd352226437db64cc8b465da36d2",
       "IPY_MODEL_6ddac7f58b8141d2ab7f4ce17d8f0d6f"
      ]
     }
    },
    "08cb7a9bfc2940abb91f5dcc6677d384": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "27d8cd352226437db64cc8b465da36d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_68feb75bf4d34bbcb79d5c86d6d62677",
      "_dom_classes": [],
      "description": "Epoch: 3 Loss: 1.962: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_82ac2425555443e1801f970b6890a128"
     }
    },
    "6ddac7f58b8141d2ab7f4ce17d8f0d6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_9f0c831a10c8462bacf0135142fed080",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [10:21&lt;00:00,  2.98it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3f0531c123c248d1a4d62018d46b661d"
     }
    },
    "68feb75bf4d34bbcb79d5c86d6d62677": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "82ac2425555443e1801f970b6890a128": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "9f0c831a10c8462bacf0135142fed080": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3f0531c123c248d1a4d62018d46b661d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c22ca3341edb4782ba336a9370e0a24a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_aa4c8616f8ac4d5aad11b4ce97c54c5e",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_47908c716e4f45e39274504aa6f6a056",
       "IPY_MODEL_4681f4f2724d4c70b48df82e1d1c1546"
      ]
     }
    },
    "aa4c8616f8ac4d5aad11b4ce97c54c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "47908c716e4f45e39274504aa6f6a056": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_d2736e5fdcd84f368cd99bdaedaa2a29",
      "_dom_classes": [],
      "description": "Epoch: 4 Loss: 1.951: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_35479529ae9643bcb103629b58fc764d"
     }
    },
    "4681f4f2724d4c70b48df82e1d1c1546": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d5692ba1dcca4abf9b03bdcc790cd6fc",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [15:37&lt;00:00,  1.98it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_9ba71a356e794fc0965a4cd58c177b1f"
     }
    },
    "d2736e5fdcd84f368cd99bdaedaa2a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "35479529ae9643bcb103629b58fc764d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d5692ba1dcca4abf9b03bdcc790cd6fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "9ba71a356e794fc0965a4cd58c177b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a2c32de011b248089b6dd315871b9e22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5880c95a4c7044a5a0557efb82cce43a",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_8f3ea17935854a84bf965c2ed966547c",
       "IPY_MODEL_b93a5869e66440dab3c315a056fc1529"
      ]
     }
    },
    "5880c95a4c7044a5a0557efb82cce43a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8f3ea17935854a84bf965c2ed966547c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_eff0f015642441c6984fe149f2da8712",
      "_dom_classes": [],
      "description": "Epoch: 5 Loss: 1.949: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3a4e83058e7645138ac3d2aa37ac223f"
     }
    },
    "b93a5869e66440dab3c315a056fc1529": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_c66a1b4f3ddc46559469544b631a2d44",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [10:21&lt;00:00,  2.98it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_806b8b9410e14909949f8b262db25041"
     }
    },
    "eff0f015642441c6984fe149f2da8712": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3a4e83058e7645138ac3d2aa37ac223f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c66a1b4f3ddc46559469544b631a2d44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "806b8b9410e14909949f8b262db25041": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ee39bcceccf34c05a1f12afc093e5b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_6fd8ba913cf64e0c9012c9cf6516958e",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_7e42bfbe6cf846ff869a77ae811066fe",
       "IPY_MODEL_896ce37770fa43ac9edca86d7208c671"
      ]
     }
    },
    "6fd8ba913cf64e0c9012c9cf6516958e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "7e42bfbe6cf846ff869a77ae811066fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_acd5c6b0b2bd48b299bea2ed97b20f5b",
      "_dom_classes": [],
      "description": "Epoch: 6 Loss: 1.955: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0b91fb288e9a425cbbda382f72d105d5"
     }
    },
    "896ce37770fa43ac9edca86d7208c671": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2816075c5c824dc28136930d6f82bb89",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [15:32&lt;00:00,  1.99it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_dc64ed1ad4c44e5485ad08901d95bfc4"
     }
    },
    "acd5c6b0b2bd48b299bea2ed97b20f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0b91fb288e9a425cbbda382f72d105d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2816075c5c824dc28136930d6f82bb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "dc64ed1ad4c44e5485ad08901d95bfc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "910602ff3a1f46e99dc8de0d3b3b5406": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_160b3ad2c96b4f77ac0517f3e6fb8208",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d010b89d9e2c44c6abfd811595259af1",
       "IPY_MODEL_352993ca07d44a01b43e2b00c5fc98e3"
      ]
     }
    },
    "160b3ad2c96b4f77ac0517f3e6fb8208": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d010b89d9e2c44c6abfd811595259af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_f3d6d13a4f5c4dab9b4ead28e651dba9",
      "_dom_classes": [],
      "description": "Epoch: 7 Loss: 1.971: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ae1e0febaa5341cfb8478bc819f5b8ef"
     }
    },
    "352993ca07d44a01b43e2b00c5fc98e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_8affd13229cf4709a0a5f33180b210ba",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [10:21&lt;00:00,  2.99it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f88a4f879e12489fab55238667a68010"
     }
    },
    "f3d6d13a4f5c4dab9b4ead28e651dba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ae1e0febaa5341cfb8478bc819f5b8ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8affd13229cf4709a0a5f33180b210ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f88a4f879e12489fab55238667a68010": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "1966d8ca5fa246e0960642d8f8b8e7ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d152f6dd8d3845749022df9078645d3e",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_449b8a78bace40a7b5a1e62f933868d8",
       "IPY_MODEL_5d74eac4457d414a8e44168403fd2b95"
      ]
     }
    },
    "d152f6dd8d3845749022df9078645d3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "449b8a78bace40a7b5a1e62f933868d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_af7111b0095e4d28abe82a70e25758f9",
      "_dom_classes": [],
      "description": "Epoch: 8 Loss: 1.996: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1855,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_feca10f4b64d486fb2b0dc4297945baa"
     }
    },
    "5d74eac4457d414a8e44168403fd2b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_308cab5fd9e845d394a3275ced2ba3d1",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1855/1855 [10:21&lt;00:00,  2.98it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_1dff8809033f4656a8cf9d4d9a4ca7eb"
     }
    },
    "af7111b0095e4d28abe82a70e25758f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "feca10f4b64d486fb2b0dc4297945baa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "308cab5fd9e845d394a3275ced2ba3d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "1dff8809033f4656a8cf9d4d9a4ca7eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "dfa1ba1a520349b8b4168392807e7574": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_68aaa81e05a44734bf703ade82c42ee7",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_3f6a9b486f2f46239bbd2f6e34b0d16b",
       "IPY_MODEL_31889c304af249a7a9ac7ae5e505de9e"
      ]
     }
    },
    "68aaa81e05a44734bf703ade82c42ee7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3f6a9b486f2f46239bbd2f6e34b0d16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_4010f561285f4d82b7e37d7c9bc17d1f",
      "_dom_classes": [],
      "description": "Epoch: 9 Loss: 2.0:   3%",
      "_model_name": "FloatProgressModel",
      "bar_style": "",
      "max": 1855,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 54,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ff59f90710d84d63bd25e065b7a72e39"
     }
    },
    "31889c304af249a7a9ac7ae5e505de9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_c819ab9ca3864854adb040179e66634e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 54/1855 [00:18&lt;10:05,  2.97it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_1bb8a2a27a9c41d2a853e39eabb987f0"
     }
    },
    "4010f561285f4d82b7e37d7c9bc17d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ff59f90710d84d63bd25e065b7a72e39": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c819ab9ca3864854adb040179e66634e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "1bb8a2a27a9c41d2a853e39eabb987f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1tA4eBQ-p7H"
   },
   "source": [
    "<center><h3>**Welcome to the Knowledge Distillation Notebook.**</h3></center>\n",
    "\n",
    "This notebook is an experimental part of the homework and not worth points. It is not guaranteed to work correctly. \n",
    "\n",
    "A trend in Natural Language Processing is to pretrain large models that can then be fine-tuned for specific problems. However the state-of-the-art models can be quite large: the \"base\" BERT model has 110M parameters and the \"large\" BERT model has 350M parameters! In many applications, such as client-side mobile apps, we do not have the compute to run the BERT model even in an evaluation setting.\n",
    "\n",
    "Here we look at a method for reducing model size, called Knowledge Distillation. Specifically, we will follow the paper __[TinyBERT: Distilling BERT for Natural Language Understanding](https://arxiv.org/abs/1909.10351)__.\n",
    "In this assignment you will:\n",
    "- Use an off-the-shelf API to replicate a paper method\n",
    "- Implement loss functions for KD as specified by the paper\n",
    "\n",
    "**Before You Get Started**\n",
    "\n",
    "Read the Paper. Also, the API we will be using is the Transformers API released by HuggingFace. It may be helpful to look at the __[documentation](https://huggingface.co/transformers/)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQIyP__s-p7g"
   },
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UO1rSB3s_Ed5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623576347658,
     "user_tz": -120,
     "elapsed": 7042,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    }
   },
   "source": [
    "#block the output to keep not pollute the notebook\n",
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8frISYlT_Lri",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623576352189,
     "user_tz": -120,
     "elapsed": 411,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "e005a75b-e487-418a-e2dc-c733728501e5"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "DRIVE=True"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgPvRlHl-p7j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623576354636,
     "user_tz": -120,
     "elapsed": 374,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "97db73e2-7166-4e3e-eca0-9f6f84c61f24"
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Ih0h2mU-p7m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623576378478,
     "user_tz": -120,
     "elapsed": 6605,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "8bdacb33-1530-44d1-cf6e-3cc892dba25c"
   },
   "source": [
    "root_folder = \"\" if not DRIVE else \"/content/drive/MyDrive/cs182_hw3/\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(root_folder)\n",
    "import json\n",
    "from utils import validate_to_array, model_out_to_list\n",
    "import torch as th\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import math\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "# device = th.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertConfig, BertForPreTraining"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "cuda\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Sqe9HiM-p7q"
   },
   "source": [
    "# BERT Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6PbKRQD-p7s"
   },
   "source": [
    "First load the BERT base model and take a look at the architecture. Don't mind the warnings for now. Based on the nn.Module names, what major component from the Transformer architecture in \"Attention is All You Need\" is substantially smaller in the BERT model? What is the purpose of the component?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0dtE6Y0-p7t"
   },
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjJWcena-p7v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623576659269,
     "user_tz": -120,
     "elapsed": 34885,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "e7809da8-9fdd-4749-c10a-0346fa641007"
   },
   "source": [
    "%%capture\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)\n",
    "teacher_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\").to(device)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRp-Utp7-p7x",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623576807669,
     "user_tz": -120,
     "elapsed": 358,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "5f7b99d4-691e-436b-d37b-4326b267e356"
   },
   "source": [
    "print(teacher_model)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "BertForMaskedLM(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls): BertOnlyMLMHead(\n",
      "    (predictions): BertLMPredictionHead(\n",
      "      (transform): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3vhv5zl-p7z"
   },
   "source": [
    "# KD Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5AUU7sv-p70"
   },
   "source": [
    "First, we need to access the intermediate layer outputs of the model. Read section 3 of the paper and take a look at the documentation for __[the forward function](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel.forward)__, or look at the docstring below. Fill in the kwargs to retrieve the necessary outputs from the model. Note that the returning the embedding is not an option, you can retrieve the embeddings via a method attribute of BERT, `get_input_embeddings(self)`. Consider what an Embedding is; why wouldn't we need to return an embedding for every sample in a batch?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C-nAHNNw-p72",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623577820169,
     "user_tz": -120,
     "elapsed": 342,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    }
   },
   "source": [
    "forward_kwargs = dict(\n",
    "    output_attentions=True,\n",
    "    output_hidden_states=True,\n",
    "    return_dict=True,\n",
    ")"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rP1TlYYJ-p73",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623577568270,
     "user_tz": -120,
     "elapsed": 358,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "88211a56-9105-4c29-ae56-cac959110362"
   },
   "source": [
    "help(teacher_model.forward)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Help on method forward in module transformers.models.bert.modeling_bert:\n",
      "\n",
      "forward(input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None, labels=None, output_attentions=None, output_hidden_states=None, return_dict=None) method of transformers.models.bert.modeling_bert.BertForMaskedLM instance\n",
      "    The :class:`~transformers.BertForMaskedLM` forward method, overrides the :func:`__call__` special method.\n",
      "    \n",
      "    .. note::\n",
      "        Although the recipe for forward pass needs to be defined within this function, one should call the\n",
      "        :class:`Module` instance afterwards instead of this since the former takes care of running the pre and post\n",
      "        processing steps while the latter silently ignores them.\n",
      "        \n",
      "    Args:\n",
      "        input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):\n",
      "            Indices of input sequence tokens in the vocabulary.\n",
      "    \n",
      "            Indices can be obtained using :class:`~transformers.BertTokenizer`. See\n",
      "            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for\n",
      "            details.\n",
      "    \n",
      "            `What are input IDs? <../glossary.html#input-ids>`__\n",
      "        attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
      "            Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n",
      "    \n",
      "            - 1 for tokens that are **not masked**,\n",
      "            - 0 for tokens that are **masked**.\n",
      "    \n",
      "            `What are attention masks? <../glossary.html#attention-mask>`__\n",
      "        token_type_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
      "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in ``[0,\n",
      "            1]``:\n",
      "    \n",
      "            - 0 corresponds to a `sentence A` token,\n",
      "            - 1 corresponds to a `sentence B` token.\n",
      "    \n",
      "            `What are token type IDs? <../glossary.html#token-type-ids>`_\n",
      "        position_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
      "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range ``[0,\n",
      "            config.max_position_embeddings - 1]``.\n",
      "    \n",
      "            `What are position IDs? <../glossary.html#position-ids>`_\n",
      "        head_mask (:obj:`torch.FloatTensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`):\n",
      "            Mask to nullify selected heads of the self-attention modules. Mask values selected in ``[0, 1]``:\n",
      "    \n",
      "            - 1 indicates the head is **not masked**,\n",
      "            - 0 indicates the head is **masked**.\n",
      "    \n",
      "        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n",
      "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
      "            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated\n",
      "            vectors than the model's internal embedding lookup matrix.\n",
      "        output_attentions (:obj:`bool`, `optional`):\n",
      "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n",
      "            tensors for more detail.\n",
      "        output_hidden_states (:obj:`bool`, `optional`):\n",
      "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n",
      "            more detail.\n",
      "        return_dict (:obj:`bool`, `optional`):\n",
      "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n",
      "    \n",
      "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
      "            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n",
      "            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n",
      "            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n",
      "        \n",
      "    Returns:\n",
      "        :class:`~transformers.modeling_outputs.MaskedLMOutput` or :obj:`tuple(torch.FloatTensor)`: A :class:`~transformers.modeling_outputs.MaskedLMOutput` (if\n",
      "        ``return_dict=True`` is passed or when ``config.return_dict=True``) or a tuple of :obj:`torch.FloatTensor`\n",
      "        comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs.\n",
      "    \n",
      "        - **loss** (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`labels` is provided) -- Masked language modeling (MLM) loss.\n",
      "        - **logits** (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`) -- Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
      "        - **hidden_states** (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``) -- Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
      "          of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
      "    \n",
      "          Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
      "        - **attentions** (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``) -- Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n",
      "          sequence_length, sequence_length)`.\n",
      "    \n",
      "          Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
      "          heads.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> from transformers import BertTokenizer, BertForMaskedLM\n",
      "        >>> import torch\n",
      "    \n",
      "        >>> tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
      "        >>> model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
      "    \n",
      "        >>> inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
      "        >>> labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
      "    \n",
      "        >>> outputs = model(**inputs, labels=labels)\n",
      "        >>> loss = outputs.loss\n",
      "        >>> logits = outputs.logits\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEgc5DzN-p75"
   },
   "source": [
    "Implement to EmbeddingLayerLoss, AttentionLayerLoss, HiddenLayerLoss, PredictionLoss, and KnowledgeDistillationLoss as specified in section 3 of the paper. The output of BERT will be a dictionary, look at 'return' in the documentation or the docstring for the relevant keys in the return dictionary. We will add the embedding in under 'embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SNGTQXNAz6E"
   },
   "source": [
    "## (1) Implementing the Attention Layer Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKVTOLVwBEv7"
   },
   "source": [
    "This part is located in AttentionLayerLoss in kd_loss.py. You must implement the call function of the class. You will need to implement the formula (7) in section 3 of __[TinyBERT](https://arxiv.org/pdf/1909.10351.pdf)__. Note that the actual implemetation compares raw output from attention. The transformers API returns the softmax output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNdxuQ2v6vDy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623578283005,
     "user_tz": -120,
     "elapsed": 357,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "85e7a576-c7fe-434b-a120-73749f845a62"
   },
   "source": [
    "from kd_loss import AttentionLayerLoss\n",
    "num_channels = 10\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "with open(root_folder+\"kd_checks/kd_attention_loss.json\",'r') as f:\n",
    "  io = json.load(f)\n",
    "  teacher_attn = th.tensor(io['teacher_attention'])\n",
    "  student_attn = th.tensor(io['student_attention'])\n",
    "  expected_output = th.tensor(io['expected_output'])\n",
    "\n",
    "attn_loss = AttentionLayerLoss()\n",
    "output = attn_loss(teacher_attn, student_attn)\n",
    "validate_to_array(model_out_to_list,((teacher_attn,student_attn),attn_loss),'kdattnloss', root_folder)\n",
    "print(\"Total error on the output:\",th.sum(th.abs(expected_output-output)).item(), \"(should be 0.0 or close to 0.0)\")"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Total error on the output: 0.0 (should be 0.0 or close to 0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTPdLyBTd1Vq"
   },
   "source": [
    "## (2) Implementing the Hidden Layer Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDnqWEcEd1WD"
   },
   "source": [
    "This part is located in HiddenLayerLoss in kd_loss.py. You must implement the call function of the class. You will need to implement the formula (8) in section 3 of __[TinyBERT](https://arxiv.org/pdf/1909.10351.pdf)__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1itJLead1WG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580456610,
     "user_tz": -120,
     "elapsed": 353,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "dbd49552-1585-4456-f3b8-cabd288976b3"
   },
   "source": [
    "from kd_loss import HiddenLayerLoss\n",
    "teacher_hidden_dim = 50\n",
    "student_hidden_dim = 10\n",
    "batch_size = 2\n",
    "\n",
    "with open(root_folder+\"kd_checks/kd_hidden_loss.json\",'r') as f:\n",
    "  io = json.load(f)\n",
    "  teacher_hddn = th.tensor(io['teacher_hidden'])\n",
    "  student_hddn = th.tensor(io['student_hidden'])\n",
    "  expected_output = th.tensor(io['expected_output'])\n",
    "\n",
    "hddn_loss = HiddenLayerLoss(teacher_hidden_dim,student_hidden_dim)\n",
    "hddn_loss.load_state_dict(th.load(root_folder+\"kd_checks/kd_hidden_loss\"))\n",
    "output = hddn_loss(teacher_hddn, student_hddn)\n",
    "validate_to_array(model_out_to_list,((teacher_hddn,student_hddn),hddn_loss),'kdhddnloss', root_folder)\n",
    "print(\"Total error on the output:\",th.sum(th.abs(expected_output-output)).item(), \"(should be 0.0 or close to 0.0)\")"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Total error on the output: 0.0 (should be 0.0 or close to 0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCnb9WhBte-r"
   },
   "source": [
    "## (3) Implementing the Embedding Layer Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUMedWUOte_N"
   },
   "source": [
    "This part is located in EmbedLayerLoss in kd_loss.py. You must implement the call function of the class. You will need to implement the formula (9) in section 3 of __[TinyBERT](https://arxiv.org/pdf/1909.10351.pdf)__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFegY_gNte_R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580453614,
     "user_tz": -120,
     "elapsed": 344,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "9d492526-7dc8-48d7-abae-227a20fab00c"
   },
   "source": [
    "from kd_loss import EmbeddingLayerLoss\n",
    "teacher_embed_dim = 50\n",
    "student_embed_dim = 10\n",
    "batch_size = 2\n",
    "\n",
    "with open(root_folder+\"kd_checks/kd_embed_loss.json\",'r') as f:\n",
    "  io = json.load(f)\n",
    "  teacher_embd = th.tensor(io['teacher_embed'])\n",
    "  student_embd = th.tensor(io['student_embed'])\n",
    "  expected_output = th.tensor(io['expected_output'])\n",
    "\n",
    "embd_loss = EmbeddingLayerLoss(teacher_embed_dim,student_embed_dim)\n",
    "embd_loss.load_state_dict(th.load(root_folder+\"kd_checks/kd_embed_loss\"))\n",
    "output = embd_loss(teacher_embd, student_embd)\n",
    "validate_to_array(model_out_to_list,((teacher_embd,student_embd),embd_loss),'kdembdloss', root_folder)\n",
    "print(\"Total error on the output:\",th.sum(th.abs(expected_output-output)).item(), \"(should be 0.0 or close to 0.0)\")"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Total error on the output: 0.0 (should be 0.0 or close to 0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LFwH1IPvsNV"
   },
   "source": [
    "## (4) Implementing the Prediction Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woCYlCLlvsN3"
   },
   "source": [
    "This part is located in PredictionLoss in kd_loss.py. You must implement the call function of the class. You will need to implement the formula (10) in section 3 of __[TinyBERT](https://arxiv.org/pdf/1909.10351.pdf)__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsHNe0iWvsN6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580739521,
     "user_tz": -120,
     "elapsed": 348,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "01f6ca18-a69a-4fba-cc2e-e75fcd1fba11"
   },
   "source": [
    "from kd_loss import PredictionLoss\n",
    "word_count = 10\n",
    "batch_size = 2\n",
    "\n",
    "with open(root_folder+\"kd_checks/kd_pred_loss.json\",'r') as f:\n",
    "  io = json.load(f)\n",
    "  teacher_pred = th.tensor(io['teacher_pred'])\n",
    "  student_pred = th.tensor(io['student_pred'])\n",
    "  expected_output = th.tensor(io['expected_output'])\n",
    "\n",
    "pred_loss = PredictionLoss()\n",
    "output = pred_loss(teacher_pred, student_pred)\n",
    "validate_to_array(model_out_to_list,((teacher_pred,student_pred),pred_loss),'kdpredloss', root_folder)\n",
    "print(\"Total error on the output:\",th.sum(th.abs(expected_output-output)).item(), \"(should be 0.0 or close to 0.0)\")"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Total error on the output: 0.02235579490661621 (should be 0.0 or close to 0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0Fm6jwlyRnU"
   },
   "source": [
    "## (5) Implementing the Knowledge Distillation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m5gjJyOyRn3"
   },
   "source": [
    "This part is located in KnowledgeDistillationLoss in kd_loss.py. You must implement the call function of the class. You will need to implement the formula (11) in section 3 of __[TinyBERT](https://arxiv.org/pdf/1909.10351.pdf)__"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yq2GI2UUyRn7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580746649,
     "user_tz": -120,
     "elapsed": 357,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "89174788-133e-4a22-cd8b-bb35ff8200ed"
   },
   "source": [
    "from kd_loss import KnowledgeDistillationLoss\n",
    "num_channels = 12\n",
    "teacher_hidden_dim = 60\n",
    "student_hidden_dim = 15\n",
    "teacher_embed_dim = 50\n",
    "student_embed_dim = 10\n",
    "word_count = 5\n",
    "teacher_num_blocks = 6\n",
    "student_num_blocks = 2\n",
    "batch_size = 2\n",
    "layer_mapping = range(2,6,3)\n",
    "\n",
    "with open(root_folder+\"kd_checks/kd_loss.json\",'r') as f:\n",
    "  io = json.load(f)\n",
    "  teacher_out = io['teacher_out']\n",
    "  student_out = io['student_out']\n",
    "  teacher_out = dict(\n",
    "      embeddings=th.tensor(teacher_out['embeddings']),\n",
    "      attentions=[th.tensor(o) for o in teacher_out['attentions']],\n",
    "      hidden_states=[th.tensor(o) for o in teacher_out['hidden_states']],\n",
    "      logits=th.tensor(teacher_out['embeddings'])\n",
    "  )\n",
    "  student_out = dict(\n",
    "      embeddings=th.tensor(student_out['embeddings']),\n",
    "      attentions=[th.tensor(o) for o in student_out['attentions']],\n",
    "      hidden_states=[th.tensor(o) for o in student_out['hidden_states']],\n",
    "      logits=th.tensor(student_out['embeddings'])\n",
    "  )\n",
    "  expected_output = th.tensor(io['expected_output'])\n",
    "\n",
    "kd_loss = KnowledgeDistillationLoss(teacher_embed_dim,student_embed_dim,teacher_hidden_dim,student_hidden_dim,layer_mapping)\n",
    "kd_loss.load_state_dict(th.load(root_folder+\"kd_checks/kd_loss\"))\n",
    "output = kd_loss(teacher_out, student_out)\n",
    "validate_to_array(model_out_to_list,((teacher_out,student_out),kd_loss),'kdloss', root_folder)\n",
    "print(\"Total error on the output:\",th.sum(th.abs(expected_output-output)).item(), \"(should be 0.0 or close to 0.0)\")"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Total error on the output: 0.48562049865722656 (should be 0.0 or close to 0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZFUAhfr-p8q"
   },
   "source": [
    "#Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbRwa2Dips0O"
   },
   "source": [
    "##General Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYI7sTo8DiZa"
   },
   "source": [
    "###Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_E6d-DN-p8y"
   },
   "source": [
    "Below is the text parsing set up. We will be using the wikitext dataset as used in the paper. But since we are just demonstrating the method, we will use the small wikitext-2 dataset instead of the standard wikitext-103 set. Wikitext contains thousands of cleaned English Wikipedia articles separated by sentence. Since the order of sentences is left in tact, the dataset can be used to model long term dependencies between words."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PoH6OWg0-p8z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580761045,
     "user_tz": -120,
     "elapsed": 7291,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    }
   },
   "source": [
    "%%capture\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1', )"
   ],
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGhXJ86gDr_W"
   },
   "source": [
    "See that the data has been split into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96VeMWrs-p80",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580766411,
     "user_tz": -120,
     "elapsed": 352,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "8b2114a4-d9df-44fb-f02d-715b61100116"
   },
   "source": [
    "print(datasets)"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOPPgsaGGLHb"
   },
   "source": [
    "A sample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQODO5ZMDzxo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580781336,
     "user_tz": -120,
     "elapsed": 445,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "f6d6eb85-9403-4385-c0a5-b23e6b0492b6"
   },
   "source": [
    "print(\"\".join(datasets['train'][:100]['text']))"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      " = Valkyria Chronicles III = \n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      " = = Gameplay = = \n",
      " As with previous Valkyira Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main heroines , although they take a very minor role . \n",
      " The game 's battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters ' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \n",
      " Troops are divided into five classes : Scouts , Shocktroopers , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . \n",
      " = = Plot = = \n",
      " The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task , exemplified by their motto , Altaha Abilia , meaning \" Always Ready . \" The three main characters are No.7 Kurt Irving , an army officer falsely accused of treason who wishes to redeem himself ; Ace No.1 Imca , a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and No.13 Riela Marcellis , a seemingly jinxed young woman who is unknowingly a descendant of the Valkyria . Together with their fellow squad members , these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven , consisting of mostly Darcsen soldiers . \n",
      " As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose face in the war . While at times this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain members of the 422nd great distress . One such member , Gusurg , becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , Dahau . At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their own interests . Hounded by both allies and enemies , and combined with the presence of a traitor within their ranks , the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort . This continues until the Nameless 's commanding officer , Ramsey Crowe , who had been kept under house arrest , is escorted to the capital city of Randgriz in order to present evidence exonerating the weary soldiers and expose the real traitor , the Gallian General that had accused Kurt of Treason . \n",
      " Partly due to these events , and partly due to the major losses in manpower Gallia suffers towards the end of the war with the Empire , the Nameless are offered a formal position as a squad in the Gallian Army rather than serve as an anonymous shadow force . This is short @-@ lived , however , as following Maximilian 's defeat , Dahau and Calamity Raven move to activate an ancient Valkyrian super weapon within the Empire , kept secret by their benefactor . Without the support of Maximilian or the chance to prove themselves in the war with Gallia , it is Dahau 's last trump card in creating a new Darcsen nation . As an armed Gallian force invading the Empire just following the two nations ' cease @-@ fire would certainly wreck their newfound peace , Kurt decides to once again make his squad the Nameless , asking Crowe to list himself and all under his command as killed @-@ in @-@ action . Now owing allegiance to none other than themselves , the 422nd confronts Dahau and destroys the Valkyrian weapon . Each member then goes their separate ways in order to begin their lives anew . \n",
      " = = Development = = \n",
      " Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010 , with full development beginning shortly after this . The director of Valkyria Chronicles II , Takeshi Ozawa , returned to that role for Valkyria Chronicles III . Development work took approximately one year . After the release of Valkyria Chronicles II , the staff took a look at both the popular response for the game and what they wanted to do next for the series . Like its predecessor , Valkyria Chronicles III was developed for PlayStation Portable : this was due to the team wanting to refine the mechanics created for Valkyria Chronicles II , and they had not come up with the \" revolutionary \" idea that would warrant a new entry for the PlayStation 3 . Speaking in an interview , it was stated that the development team considered Valkyria Chronicles III to be the series ' first true sequel : while Valkyria Chronicles II had required a large amount of trial and error during development due to the platform move , the third game gave them a chance to improve upon the best parts of Valkyria Chronicles II due to being on the same platform . In addition to Sega staff from the previous games , development work was also handled by Media.Vision. The original scenario was written Kazuki Yamanobe , while the script was written by Hiroyuki Fujii , Koichi Majima , Kishiko Miyagi , Seiki Nagakawa and Takayuki Shouji . Its story was darker and more somber than that of its predecessor . \n",
      " The majority of material created for previous games , such as the BLiTZ system and the design of maps , was carried over . Alongside this , improvements were made to the game 's graphics and some elements were expanded , such as map layouts , mission structure , and the number of playable units per mission . A part of this upgrade involved creating unique polygon models for each character 's body . In order to achieve this , the cooperative elements incorporated into the second game were removed , as they took up a large portion of memory space needed for the improvements . They also adjusted the difficulty settings and ease of play so they could appeal to new players while retaining the essential components of the series ' gameplay . The newer systems were decided upon early in development . The character designs were done by Raita Honjou , who had worked on the previous Valkyria Chronicles games . When creating the Nameless Squad , Honjou was faced with the same problem he had had during the first game : the military uniforms essentially destroyed character individuality , despite him needing to create unique characters the player could identify while maintaining a sense of reality within the Valkyria Chronicles world . The main color of the Nameless was black . As with the previous Valkyria games , Valkyria Chronicles III used the CANVAS graphics engine . The anime opening was produced by Production I.G. \n",
      " = = = Music = = = \n",
      " The music was composed by Hitoshi Sakimoto , who had also worked on the previous Valkyria Chronicles games . When he originally heard about the project , he thought it would be a light tone similar to other Valkyria Chronicles games , but found the themes much darker than expected . An early theme he designed around his original vision of the project was rejected . He redid the main theme about seven times through the music production due to this need to reassess the game . The main theme was initially recorded using orchestra , then Sakimoto removed elements such as the guitar and bass , then adjusted the theme using a synthesizer before redoing segments such as the guitar piece on their own before incorporating them into the theme . The rejected main theme was used as a hopeful tune that played during the game 's ending . The battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments , constructed to create a sense of atonality . While Sakimoto was most used to working with synthesized music , he felt that he needed to incorporate live instruments such as orchestra and guitar . The guitar was played by Mitsuhiro Ohta , who also arranged several of the later tracks . The game 's opening theme song , \" If You Wish for ... \" ( もしも君が願うのなら , Moshimo Kimi ga Negauno Nara ) , was sung by Japanese singer May 'n . Its theme was the reason soldiers fought , in particular their wish to protect what was precious to them rather than a sense of responsibility or duty . Its lyrics were written by Seiko Fujibayashi , who had worked on May 'n on previous singles . \n",
      " = = = Release = = = \n",
      " In September 2010 , a teaser website was revealed by Sega , hinting at a new Valkyria Chronicles game . In its September issue , Famitsu listed that Senjō no Valkyria 3 would be arriving on the PlayStation Portable . Its first public appearance was at the 2010 Tokyo Game Show ( TGS ) , where a demo was made available for journalists and attendees . During the publicity , story details were kept scant so as not to spoil too much for potential players , along with some of its content still being in flux at the time of its reveal . To promote the game and detail the story leading into the game 's events , an episodic Flash visual novel written by Fujii began release in January 2011 . The game was released January 27 , 2011 . During an interview , the development team said that the game had the capacity for downloadable content ( DLC ) , but that no plans were finalized . Multiple DLC maps , featuring additional missions and recruitable characters , were released between February and April 2011 . An expanded edition of the game , Valkyria Chronicles III Extra Edition , released on November 23 , 2011 . Packaged and sold at a lower price than the original , Extra Edition game with seven additional episodes : three new , three chosen by staff from the game 's DLC , and one made available as a pre @-@ order bonus . People who also owned the original game could transfer their save data between versions . \n",
      " Unlike its two predecessors , Valkyria Chronicles III was not released in the west . According to Sega , this was due to poor sales of Valkyria Chronicles II and the general unpopularity of the PSP in the west . An unofficial fan translation patch began development in February 2012 : players with a copy of Valkyria Chronicles III could download and apply the patch , which translated the game 's text into English . Compatible with the Extra Edition , the patch was released in January 2014 . \n",
      " = = Reception = = \n",
      " On its day of release in Japan , Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts . By early February , the game sold 102 @,@ 779 units , coming in second overall to The Last Story for the Wii . By the end of the year , the game had sold just over 152 @,@ 500 units . \n",
      " Famitsu enjoyed the story , and were particularly pleased with the improvements to gameplay . Japanese gaming site Game Watch Impress , despite negatively noting its pacing and elements recycled from previous games , was generally positive about its story and characters , and found its gameplay entertaining despite off @-@ putting difficulty spikes . 4Gamer.net writer Naohiko Misuosame , in a \" Play Test \" article based on the game 's PSN demo , felt that Valkyria Chronicles III provided a \" profound feeling of closure \" for the Valkyria Chronicles series . He praised its gameplay despite annoying limitations to aspects such as special abilities , and positively noted its shift in story to a tone similar to the first game . \n",
      " PlayStation Official Magazine - UK praised the story 's blurring of Gallia 's moral standing , art style , and most points about its gameplay , positively noting the latter for both its continued quality and the tweaks to balance and content . Its one major criticism were multiple difficulty spikes , something that had affected the previous games . Heath Hindman of gaming website PlayStation Lifestyle praised the addition of non @-@ linear elements and improvements or removal of mechanics from Valkyria Chronicles II in addition to praising the returning gameplay style of previous games . He also positively noted the story 's serious tone . Points criticized in the review were recycled elements , awkward cutscenes that seemed to include all characters in a scene for no good reason , pacing issues , and occasional problems with the game 's AI . \n",
      " In a preview of the TGS demo , Ryan Geddes of IGN was left excited as to where the game would go after completing the demo , along with enjoying the improved visuals over Valkyria Chronicles II . Kotaku 's Richard Eisenbeis was highly positive about the game , citing is story as a return to form after Valkyria Chronicles II and its gameplay being the best in the series . His main criticisms were its length and gameplay repetition , along with expressing regret that it would not be localized . \n",
      " = = Legacy = = \n",
      " Kurt and Riela were featured in the Nintendo 3DS crossover Project X Zone , representing the Valkyria series . Media.Vision would return to the series to develop Valkyria : Azure Revolution , with Ozawa returning as director . Azure Revolution is a role @-@ playing video game for the PlayStation 4 that forms the beginning of a new series within the Valkyria franchise . \n",
      " = = = Adaptations = = = \n",
      " Valkyria Chronicles 3 was adapted into a two @-@ episode original video animation series in the same year of its release . Titled Senjō no Valkyria 3 : Taga Tame no Jūsō ( 戦場のヴァルキュリア３ 誰がための銃瘡 , lit . Valkyria of the Battlefield 3 : The Wound Taken for Someone 's Sake ) , it was originally released through PlayStation Network and Qriocity between April and May 2011 . The initially @-@ planned release and availability period needed to be extended due to a stoppage to PSN during the early summer of that year . It later released for DVD on June 29 and August 31 , 2011 , with separate \" Black \" and \" Blue \" editions being available for purchase . The anime is set during the latter half of Valkyria Chronicles III , detailing a mission by the Nameless against their Imperial rivals Calamity Raven . The anime was first announced in November 2010 . It was developed by A @-@ 1 Pictures , produced by Shinji Motoyama , directed by Nobuhiro Kondō , and written by Hiroshi Ōnogi . Sakimoto 's music for the game was used in the anime . \n",
      " The anime 's title was inspired by the principle purpose of the Nameless : to suffer in battle for the goals of others . A subtitle attached to the project during development was \" The Road to Kubinka \" , which referenced the Kubinka Tank Museum in Moscow . The game 's main theme was how the characters regained their sense of self when stripped of their names and identities , along with general themes focused on war and its consequences . While making the anime , the production team were told by Sega to make it as realistic as possible , with the consequence that the team did extensive research into aspects such as what happened when vehicles like tanks were overturned or damaged . Due to it being along the same timeline as the original game and its television anime adaptation , the cast of Valkyria Chronicles could make appearances , which pleased the team . The opening theme , \" Akari ( Light ) -Tomoshibi- \" ( 灯 @-@ TOMOSHIBI- ) , was sung by Japanese singer Faylan . The ending theme , \" Someday the Flowers of Light Will Bloom \" ( いつか咲く光の花 , Itsuka Saku Hikari no Hana ) , was sung by Minami Kuribayashi . Both songs ' lyrics were written by their respective artists . \n",
      " Two manga adaptations were produced , following each of the game 's main female protagonists Imca and Riela . They were Senjō no Valkyria 3 : Namo naki Chikai no Hana ( 戦場のヴァルキュリア3 名もなき誓いの花 , lit . Valkyria of the Battlefield 3 : The Flower of the Nameless Oath ) , illustrated by Naoyuki Fujisawa and eventually released in two volumes after being serialized in Dengeki Maoh between 2011 and 2012 ; and Senjō no Valkyria 3 : -Akaki Unmei no Ikusa Otome- ( 戦場のヴァルキュリア3 -赤き運命の戦乙女- , lit . Valkyria of the Battlefield 3 -The Valkyrie of the Crimson Fate ) , illustrated by Mizuki Tsuge and eventually released in a single volume by Kadokawa Shoten in 2012 . \n",
      " = Tower Building of the Little Rock Arsenal = \n",
      " The Tower Building of the Little Rock Arsenal , also known as U.S. Arsenal Building , is a building located in MacArthur Park in downtown Little Rock , Arkansas . Built in 1840 , it was part of Little Rock 's first military installation . Since its decommissioning , The Tower Building has housed two museums . It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001 . It has also been the headquarters of the Little Rock Æsthetic Club since 1894 . \n",
      " The building receives its name from its distinct octagonal tower . Besides being the last remaining structure of the original Little Rock Arsenal and one of the oldest buildings in central Arkansas , it was also the birthplace of General Douglas MacArthur , who became the supreme commander of US forces in the South Pacific during World War II . It was also the starting place of the Camden Expedition . In 2011 it was named as one of the top 10 attractions in the state of Arkansas by Arkansas.com. \n",
      " = = Construction = = \n",
      " The arsenal was constructed at the request of Governor James Sevier Conway in response to the perceived dangers of frontier life and fears of the many Native Americans who were passing through the state on their way to the newly established Oklahoma Territory . Thirty @-@ six acres were appropriated on the outskirts of Little Rock by Major Robert B. Lee of the U.S. Army . The land had been previously used as a racetrack by the local jockey club . John Wormley Walker , a builder for the Federal Government , supervised the construction . Originally $ 14 @,@ 000 was allocated for the construction of the arsenal , but proved inadequate . The budget was later increased to $ 30 @,@ 000 . Work began on the Tower Building in 1840 , and it was the first permanent structure of the arsenal to be built . Being originally constructed to store ammunition , the building was designed with 3 @-@ foot @-@ thick ( 0 @.@ 91 m ) exterior walls . The original plans called for it to be built of stone , however , masonry was used instead . The Arkansas Gazette referred to the structure as \" A splendid specimen of masonry \" . \n",
      " = = Civil War = = \n",
      " For several years the arsenal , which was owned by the federal government , served as a simple arms depot and was staffed with only a handful of soldiers . But in November 1860 , with the American Civil War on the horizon , a company of the Second United States Artillery , consisting of sixty @-@ five men , was transferred to Little Rock under the command of Captain James Totten . On January 15 , 1861 , the state legislature decided to hold a referendum to determine if a state convention should be held to consider the issue of secession and to elect delegates to such a convention . It was planned for February 18 ; however , events at the arsenal , would not wait . On January 28 , then Governor Henry Massey Rector informed Captain Totten that he and his soldiers would be \" permitted to remain in the possession of the Federal officers until the State , by authority of the people , shall have determined to sever their connection with the General Government , \" Totten responded to this by telling the Governor that his orders came from the United States Government and began a desperate but ultimately futile dispatch of letters and telegrams asking for reinforcements , although rumors were widely spread that they were already coming . The first telegraph wire to span between Little Rock and Memphis had recently been completed . Local attorney John M Harrel was asked to compose the first telegraph dispatched from Arkansas 's capital . In his message , Harrel reported unconfirmed rumors that more federal troops had been sent to reinforce the Little Rock Arsenal . \n",
      " The United States troops at the outposts of the western frontier of the state and in the Indian nation have all been recalled from winter quarters to reinforce the garrison at Fort Smith . The garrison at Fort Smith had been previously transferred to the United States Arsenal in this city ( Little Rock ) . The arsenal is one of the richest depositories of military stores in the United States and is supposed to be the ultimate destination of the tropps [ sic ] ordered from the frontier . \n",
      " -John M Harrel Telegram , January 31 , 1861 \n",
      " The item was intended simply as a piece of news , but telegraph lines quickly spread the news throughout the state , fueling procession sentiment . The rumor was interpreted by some Arkansans as a call from the governor to assemble to help expel the federal troops from the arsenal . By February 5 , six militia units , consisting of 1 @,@ 000 men , with a guarantee that the numbers could be increased to 5 @,@ 000 if the situations deemed it necessary , had assembled in Little Rock . Governor Rector vehemently denied ordering the troops to assemble or giving any order at all in connection with the troops . Faced with the fact that the military had assembled believing they were following his orders and the consensus of the citizens of Little Rock against any armed conflict between the civilian army and federal troops , Governor Rector was forced to take control of the situation . On February 6 , he sent a formal demand for surrender of the arsenal to Captain Totten , \n",
      " This movement is prompted by the feeling that pervades the citizens of this State that in the present emergency the arms and munitions of war in the Arsenal should be under the control of the State authorities , in order to their security . This movement , although not authorized by me , has assumed such an aspect that it becomes my duty , as the executive of this Sate , to interpose my official authority to prevent a collision between the people of the State and the Federal troops under your command . I therefore demand in the name of the State the delivery of the possession of the Arsenal and munitions of war under your charge to the State authorities , to be held subject to the action of the convention to be held on the 4th of March next . \n",
      " Perhaps because Abraham Lincoln had not yet been inaugurated as President , Captain Totten received no instructions from his superiors and was forced to withdraw his troops . He agreed to surrender the arsenal as long as the governor agreed to three provisions : \n",
      " The governor would take possession of the arsenal in the name of the United States . \n",
      " The soldiers would be allowed safe passage in any direction carrying any personal and public property besides munitions of war . \n",
      " The soldiers would be allowed to march away as men leaving under orders , not as conquered and surrendering soldiers . \n",
      " On the morning of February 8 , 1861 , Rector and Totten signed an agreement placing the arsenal in the hands of state officials . That afternoon , the citizen militia marched to the arsenal with Governor Rector at its head . All of the federal troops had left at this point , except Totten who had stayed behind to listen to the Governor 's speech and to hand the arsenal over in person . \n",
      " The Little Rock Arsenal was classified in 1860 as an \" arsenal of deposit , \" meaning that it was simply a warehouse for the storage of weapons intended for the use of the state militia in times of crisis . Thus there were no substantial operations for ordnance fabrication or repairs , nor for the manufacture of cartridges at the time the Arsenal fell into State hands . Most of these operations were started from scratch through the efforts of the Arkansas Military Board . \n",
      " Inside the Little Rock Arsenal after its seizure in February , 1861 , the Confederates inventoried some 10 @,@ 247 weapons , 250 @,@ 000 musket cartridges , and 520 @,@ 000 percussion caps , as well as the four bronze cannon of Totten 's battery . Long arms in the Arsenal 's inventory consisted of : \n",
      " M1822 .69 cal ( flintlock ) 5 @,@ 625 \n",
      " M1822 .69 cal ( percussion @-@ converted ) 53 \n",
      " M1842 .69 cal smoothbore ( percussion ) 357 \n",
      " M1855 .58 cal rifle @-@ muskets 900 \n",
      " M1817 common rifles 125 \n",
      " M1841 rifle ( \" Mississippi Rifle \" ) 54 \n",
      " M1847 musketoon 2 \n",
      " Hall 's carbines 267 \n",
      " Hall 's rifles ( flintlock ) 2 @,@ 864 \n",
      " Total 10 @,@ 247 \n",
      " Of this number , approximately 9600 weapons were serviceable , or ready @-@ for @-@ issue . Note there were only 1 @,@ 364 percussion weapons available . Disposition of the weapons found in the Arsenal is somewhat sketchy , but from various records it can be surmised that the 5th , 6th , 7th , and 8th Arkansas Infantry Regiments , mustered in June , 1861 , were issued M1816 / M1822 .69 caliber flintlocks . The 9th and 10th Arkansas , four companies of Kelly 's 9th Arkansas Battalion , and the 3rd Arkansas Cavalry Regiment were issued flintlock Hall 's Rifles . The units comprising the infantry force of Van Dorn 's Army of the West were the 1st and 2nd Arkansas Mounted Rifles were also armed with M1822 flintlocks from the Little Rock Arsenal . By the time the 11th and 12th Arkansas Infantry Regiments mustered in at Little Rock , the supply of arms had been almost completely exhausted , and only old \" junker \" weapons were left . \n",
      " Most of the equipment , arms , and machinery at the Little Rock Arsenal was removed to east of the Mississippi River by order of Maj. Gen. Earl Van Dorn in April and May 1862 , and accountability for it is lost at that point . By all appearances , the equipment was sent down the river to Napoleon , Arkansas , and from there to Jackson Mississippi , where it was probably destroyed during the Vicksburg campaign in the early summer of 1863 . \n",
      " Major General Thomas C. Hindman , sent to command the district of Arkansas in May , 1862 , found the state nearly destitute of military material . Hindman established another armory at Arkadelphia , and revived the Little Rock Arsenal as a collection point and depot for armaments and ammunition manufacture for small arms . Hindman recorded : \n",
      " \" Machinery was made for manufacturing percussion caps and small arms , and both were turned out in small quantity , but of excellent quality . Lead mines were opened and worked , and a chemical laboratory was established and successfully operated in aid of the Ordnance Department and in the manufacture of calomel , castor oil , spirits of nitre , the various tinctures of iron , and other valuable medicines . Most of these works were located at or near Arkadelphia on the Ouachita River , 75 miles south from Little Rock . The tools , machinery , and the material were gathered piecemeal or else made by hand labor . Nothing of this sort had been before attempted on Government account in Arkansas to my knowledge , except for the manufacture of small arms , the machinery for which was taken away by General Van Dorn and there was neither capital nor sufficient enterprise among the citizens to engage in such undertakings � A further supply , along with lead and caps , was procured from the citizens of Little Rock and vicinity by donation , purchases , and impressments . \n",
      " This ammunition , and that which I brought with me , was rapidly prepared for use at the Laboratory established at the Little Rock Arsenal for that purpose . As illustrating as the pitiful scarcity of material in the country , the fact may be stated that it was found necessary to use public documents of the State Library for cartridge paper . Gunsmiths were employed or conscripted , tools purchased or impressed , and the repair of the damaged guns I brought with me and about an equal number found at Little Rock commenced at once . But , after inspecting the work and observing the spirit of the men I decided that a garrison 500 strong could hold out against Fitch and that I would lead the remainder - about 1500 - to Gen 'l Rust as soon as shotguns and rifles could be obtained from Little Rock instead of pikes and lances , with which most of them were armed . Two days elapsed before the change could be effected . \" \n",
      " The Confederate ordnance establishment at Little Rock was reactivated in August , 1862 . Looking around for a suitable person to head this activity , General Hindman turned to the Confederate Navy and borrowed Lieutenant John W. Dunnington . Lt. Dunnington was the commander of the gunboat C.S.S. Ponchartrain , which had been brought to Little Rock in hopes of converting it to an ironclad . Dunnington was selected to head the ordnance works at Little Rock , and although he continued to draw his pay from the Confederate Navy Department , he was placed in charge of all Confederate ordnance activities ( which included artillery functions ) there with the rank of lieutenant colonel . \n",
      " Lt. Col. Dunnington 's \" Returns for the month of August , 1862 , at Little Rock Arsenal , C.S.A. , \" are found in Vol . 149 , Chapter IV of the \" Captured Rebel Ordnance Records , \" and are most enlightening as to the scope of Confederate ordnance activities at Little Rock during this crucial time . According to Dunnington , \" When I assumed command at this Post , all material had been removed to Arkadelphia . There were no persons employed . No shops were open for repair of arms or for fabricating ammunition . Material , tools , etc . , had to be procured as well as the employment of laborers . Work commenced the last part of the month . \" \n",
      " The military force at Little Rock under Dunnington 's command consisted of four officers : himself , Major John B. Lockman , Captain C.C. Green , and 2nd Lt. W.W. Murphy . In addition to these , he had 20 enlisted men and a civilian force composed of a foreman , 2 clerks , 3 gunsmiths for repairing small arms , a laboratorian , 26 laborers in the ammunition laboratory , and a carpenter for making packing boxes . \n",
      " During the month of August , 1862 , the following work was performed : \" Fabricated : one pair of musket bullet moulds ; 10 @,@ 000 buck & ball shot cartridges ; repaired : 750 muskets , shotguns , and rifles ; received and repaired : ordnance stores and ordnances ; performed : guard , office , and police duties ; inspected : Posts at Camden and Arkadelphia . \" \n",
      " Lt. Col. Dunnington continued to build up his works at Little Rock until November 1862 , when Captain Sanford C. Faulkner ( composer of The Arkansas Traveler ) was placed in charge of the Arsenal . Dunnington presumably returned to his naval duties and the Ponchartrain . \n",
      " A \" Summary of the Work Done for November , 1862 , Little Rock Arsenal \" shows : Fabrication : \n",
      " 75 @,@ 000 buck & ball cartridges - percussion \n",
      " 14 @,@ 000 buck & ball cartridges - flint \n",
      " 275 paper fuzes \n",
      " 117 rounds , 6 @-@ pounder canister shot \n",
      " 130 rounds , 6 @-@ pounder ball shot \n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCqAtGMyGQoo"
   },
   "source": [
    "The words must be parsed and hashed according to the vocabulary of our model. Instead of masking sentences to equal length, this time we will separate the contiguous text sequence into equal size blocks, possibly breaking up whole sentences."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yK5jjAPu-p82",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580891849,
     "user_tz": -120,
     "elapsed": 70935,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "ace08bc0-c38e-46fb-d826-7af0ee8f3494"
   },
   "source": [
    "%%capture\n",
    "tokenized_datasets = datasets.map(lambda samples: tokenizer(samples['text']), batched=True, num_proc=4, remove_columns=[\"text\"])"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x1lM3fWe-p84",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580917127,
     "user_tz": -120,
     "elapsed": 337,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    }
   },
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mQhOTXOi-p87",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580942863,
     "user_tz": -120,
     "elapsed": 22971,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    }
   },
   "source": [
    "%%capture\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=False\n",
    ")"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "l3-FYlcd-p89",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580950907,
     "user_tz": -120,
     "elapsed": 399,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "793be149-11af-457c-d132-d65384a8865f"
   },
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'the first game and follows the \" nameless \", a penal military unit serving the nation of gallia during the second europan war who perform secret black operations and are pitted against the imperial unit \" calamaty raven \". [SEP] [CLS] the game began development in 2010, carrying over a large portion of the work done on valkyria chronicles ii. while it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. character designer raita honjou and composer hitoshi sakimoto both returned from previous entries, along with valkyria chronicles ii director takeshi'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 63
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzsJJQ4S-p8_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623580961847,
     "user_tz": -120,
     "elapsed": 343,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "48dbf901-f8f4-4c0e-c528-586bb3b94f87"
   },
   "source": [
    "lm_datasets[\"train\"][1].keys()"
   ],
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['attention_mask', 'input_ids', 'labels', 'token_type_ids'])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 64
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "errlsVm6A_tC"
   },
   "source": [
    "### Set Up Student Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRhmgXFo-p8u"
   },
   "source": [
    "Fill in the dimensions of BERT and the student network as specified in section 4.2 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bLpqNBPD-p8v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623582406389,
     "user_tz": -120,
     "elapsed": 3,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    }
   },
   "source": [
    "vocab_size = int(1e4)\n",
    "teacher_hddn_dim = 768\n",
    "student_hddn_dim = 312\n",
    "teacher_num_hddn_layers = 12\n",
    "student_num_hddn_layers =  4\n",
    "teacher_num_attn_heads = 12\n",
    "student_num_attn_heads = 12\n",
    "teacher_ff_dim = 3072\n",
    "student_ff_dim = 1200\n",
    "teacher_embd_dim = 768\n",
    "student_embd_dim = 312\n",
    "layer_mapping = range(1, 12, 3)\n",
    "\n",
    "student_config = BertConfig(\n",
    "    hidden_size=student_hddn_dim,\n",
    "    num_hidden_layers=student_num_hddn_layers,\n",
    "    num_attention_heads=student_num_attn_heads,\n",
    "    intermediate_size=student_ff_dim,\n",
    ")"
   ],
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhOW156Br6Y1"
   },
   "source": [
    "###Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BoLfKJ5wSuoD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623582412931,
     "user_tz": -120,
     "elapsed": 5122,
     "user": {
      "displayName": "Axel Brunnbauer",
      "photoUrl": "",
      "userId": "08839057165606835636"
     }
    },
    "outputId": "e992d4a4-a9fe-4ad2-b748-1675f39fbe02"
   },
   "source": [
    "from kd_loss import KnowledgeDistillationLoss\n",
    "teacher_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\", cache_dir=root_folder+'bert_models').to(device)\n",
    "#teacher_model.load_state_dict(th.load(root_folder+'bert_models/teacher_wikitext.pt'))\n",
    "student_model = BertForMaskedLM(student_config).to(device)\n",
    "criterion = KnowledgeDistillationLoss(teacher_embd_dim,student_embd_dim,teacher_hddn_dim,student_hddn_dim,layer_mapping).to(device)\n"
   ],
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "3e8d78e11edd4bb7a1d9c54ac7ca5d3e",
      "e536fad866fb4c7ea4f7cd088da1fa3b",
      "1266283a54df4266a64f498e518c17d3",
      "f062005aed5448359d3dedd1f11f5f2e",
      "98a9522709894f769205f07491ea6ab1",
      "3fe45f951a1f4457aef8d9ad59f37bb6",
      "a7357f9832674730be4ebae17880e9ce",
      "74ca3486b014477281a7b7f324cc2023",
      "480d6e368ef64f0685a02ff1c2d3bcb7",
      "6c4f3dc4e9554ad6b03ada65704c8460",
      "df64a0a5d79546858d5e1b2523c1f785",
      "202b1639588740fcaf57e6813e9dcc01",
      "8547184ee853490c8841e6a9aa05981d",
      "37f0f106849e4c5fa0a0ffc6c7517f16",
      "5452b9600ebf4a6fa7236a22fa2057d0",
      "9047cb0463384e028c8588a67ed61d3d",
      "39e76015f3074852b2b9b770a23d1766",
      "0401cb9c17e242289c6c834971c5e9ce",
      "21fed3174f87442aa15bb1848f7495a7",
      "8bad6eafc2b94d49886a931d7da07497",
      "4f8f3be4b6db48af989b8d3b7b787f53",
      "6114a59730174ebebdb51ab6f238bcc5",
      "62ce9c634911447d8b56d1f6e3cea069",
      "14ae9113d91f46b59f1308718f2df0a6",
      "733730ba3556461fb39ea30db3a5542c",
      "08cb7a9bfc2940abb91f5dcc6677d384",
      "27d8cd352226437db64cc8b465da36d2",
      "6ddac7f58b8141d2ab7f4ce17d8f0d6f",
      "68feb75bf4d34bbcb79d5c86d6d62677",
      "82ac2425555443e1801f970b6890a128",
      "9f0c831a10c8462bacf0135142fed080",
      "3f0531c123c248d1a4d62018d46b661d",
      "c22ca3341edb4782ba336a9370e0a24a",
      "aa4c8616f8ac4d5aad11b4ce97c54c5e",
      "47908c716e4f45e39274504aa6f6a056",
      "4681f4f2724d4c70b48df82e1d1c1546",
      "d2736e5fdcd84f368cd99bdaedaa2a29",
      "35479529ae9643bcb103629b58fc764d",
      "d5692ba1dcca4abf9b03bdcc790cd6fc",
      "9ba71a356e794fc0965a4cd58c177b1f",
      "a2c32de011b248089b6dd315871b9e22",
      "5880c95a4c7044a5a0557efb82cce43a",
      "8f3ea17935854a84bf965c2ed966547c",
      "b93a5869e66440dab3c315a056fc1529",
      "eff0f015642441c6984fe149f2da8712",
      "3a4e83058e7645138ac3d2aa37ac223f",
      "c66a1b4f3ddc46559469544b631a2d44",
      "806b8b9410e14909949f8b262db25041",
      "ee39bcceccf34c05a1f12afc093e5b65",
      "6fd8ba913cf64e0c9012c9cf6516958e",
      "7e42bfbe6cf846ff869a77ae811066fe",
      "896ce37770fa43ac9edca86d7208c671",
      "acd5c6b0b2bd48b299bea2ed97b20f5b",
      "0b91fb288e9a425cbbda382f72d105d5",
      "2816075c5c824dc28136930d6f82bb89",
      "dc64ed1ad4c44e5485ad08901d95bfc4",
      "910602ff3a1f46e99dc8de0d3b3b5406",
      "160b3ad2c96b4f77ac0517f3e6fb8208",
      "d010b89d9e2c44c6abfd811595259af1",
      "352993ca07d44a01b43e2b00c5fc98e3",
      "f3d6d13a4f5c4dab9b4ead28e651dba9",
      "ae1e0febaa5341cfb8478bc819f5b8ef",
      "8affd13229cf4709a0a5f33180b210ba",
      "f88a4f879e12489fab55238667a68010",
      "1966d8ca5fa246e0960642d8f8b8e7ba",
      "d152f6dd8d3845749022df9078645d3e",
      "449b8a78bace40a7b5a1e62f933868d8",
      "5d74eac4457d414a8e44168403fd2b95",
      "af7111b0095e4d28abe82a70e25758f9",
      "feca10f4b64d486fb2b0dc4297945baa",
      "308cab5fd9e845d394a3275ced2ba3d1",
      "1dff8809033f4656a8cf9d4d9a4ca7eb",
      "dfa1ba1a520349b8b4168392807e7574",
      "68aaa81e05a44734bf703ade82c42ee7",
      "3f6a9b486f2f46239bbd2f6e34b0d16b",
      "31889c304af249a7a9ac7ae5e505de9e",
      "4010f561285f4d82b7e37d7c9bc17d1f",
      "ff59f90710d84d63bd25e065b7a72e39",
      "c819ab9ca3864854adb040179e66634e",
      "1bb8a2a27a9c41d2a853e39eabb987f0"
     ]
    },
    "id": "TTwV3Lwc-p9E",
    "outputId": "449e6865-6e10-4eb5-f4ca-b6f922cdd9a6"
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "gc.collect()\n",
    "optimizer = optim.Adam(params=student_model.parameters(),lr=5e-5,weight_decay=0.01)\n",
    "student_model.to(device)\n",
    "lr = 1e-4\n",
    "batch_size = 10\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    lm_datasets[\"train\"].shuffle(load_from_cache_file=False)\n",
    "    t = tqdm(range(0,len(lm_datasets[\"train\"]),batch_size))\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i in t:\n",
    "        data = lm_datasets[\"train\"][i:i+batch_size]\n",
    "        data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "        teacher_out = teacher_model(**data,**forward_kwargs)\n",
    "        student_out = student_model(**data,**forward_kwargs)\n",
    "        teacher_out['embeddings'] = teacher_model.get_input_embeddings().weight\n",
    "        student_out['embeddings'] = student_model.get_input_embeddings().weight\n",
    "        loss = criterion(teacher_out,student_out,penalize_prediction=False)\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = th.eq(student_out['logits'].argmax(dim=2,keepdim=False).float(),data['labels']).float().mean()\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        loss = np.around(np.mean(losses[-100:]),3)\n",
    "        accuracy = np.around(np.mean(accuracies[-100:]),2)\n",
    "        t.set_description(\"Epoch: \"+str(epoch)+\" Loss: \"+str(loss))\n",
    "    os.makedirs(root_folder+'bert_models',exist_ok=True)\n",
    "    th.save(student_model.state_dict(),root_folder+'bert_models/student_wikitext.pt')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8d78e11edd4bb7a1d9c54ac7ca5d3e",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480d6e368ef64f0685a02ff1c2d3bcb7",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e76015f3074852b2b9b770a23d1766",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733730ba3556461fb39ea30db3a5542c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22ca3341edb4782ba336a9370e0a24a",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c32de011b248089b6dd315871b9e22",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee39bcceccf34c05a1f12afc093e5b65",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910602ff3a1f46e99dc8de0d3b3b5406",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1966d8ca5fa246e0960642d8f8b8e7ba",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa1ba1a520349b8b4168392807e7574",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1855.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PMK0aI-os6U"
   },
   "source": [
    "We next train a control, which is just the same BERT shaped student model trained from scratch on general and task specific data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NiJZ7nXajRl3"
   },
   "source": [
    "control_model = BertForMaskedLM(student_config).to(device)\n",
    "gc.collect()\n",
    "control_model.train()\n",
    "optimizer = optim.Adam(params=student_model.parameters(),lr=lr,weight_decay=0.01)\n",
    "lr = 1e-4\n",
    "batch_size = 10\n",
    "epochs=1\n",
    "for epoch in range(epochs):\n",
    "    lm_datasets[\"train\"].shuffle()\n",
    "    t = tqdm(range(0,len(lm_datasets[\"train\"]),batch_size))\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i in t:\n",
    "        data = lm_datasets[\"train\"][i:i+batch_size]\n",
    "        data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "        student_out = student_model(**data,**forward_kwargs)\n",
    "        losses.append(student_out['loss'].detach().cpu().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        student_out['loss'].backward()\n",
    "        optimizer.step()\n",
    "        accuracy = th.eq(student_out['logits'].argmax(dim=2,keepdim=False).float(),data['labels']).float().mean()\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        loss = np.around(np.mean(losses[-100:]),3)\n",
    "        accuracy = np.around(np.mean(accuracies[-100:]),2)\n",
    "        t.set_description(\"Epoch: \"+str(epoch)+\" Loss: \"+str(loss))\n",
    "    os.makedirs(root_folder+'bert_models',exist_ok=True)\n",
    "    th.save(control_model.state_dict(),root_folder+'bert_models/control_wikitext.pt')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSGZJmYIpZdq"
   },
   "source": [
    "##Task Specific Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USC3GiVeqZMN"
   },
   "source": [
    "###Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vjJWERd7-p9Q",
    "scrolled": false
   },
   "source": [
    "%%capture\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset('glue', 'mrpc')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIf7dyt8qnw-"
   },
   "source": [
    "See that the data has been split into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dONZeNeI-p9S"
   },
   "source": [
    "datasets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "87VliGivqv7Q"
   },
   "source": [
    "print(datasets['train'][0]['sentence1'], datasets['train'][0]['sentence2'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FqLU14b_-p9U"
   },
   "source": [
    "%%capture\n",
    "mrpc_tok = datasets.map(lambda samples: tokenizer(samples['sentence1'], samples['sentence2'],padding='max_length',max_length=150),\n",
    "                       remove_columns=['sentence1', 'sentence2','idx'],\n",
    "                       load_from_cache_file=False,\n",
    "                      )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VHHVEVkT-p9V"
   },
   "source": [
    "%%capture\n",
    "def filter_texts(examples):\n",
    "    examples[\"labels\"] = examples[\"label\"].copy()\n",
    "    examples.pop('label',None)\n",
    "    return examples\n",
    "mrpc = mrpc_tok.map(\n",
    "    filter_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=False\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n58bP7PKrnJ1"
   },
   "source": [
    "###Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nhg-b7tmsA3V"
   },
   "source": [
    "from kd_loss import KnowledgeDistillationLoss\n",
    "from transformers import BertForNextSentencePrediction, BertForSequenceClassification\n",
    "teacher_model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "teacher_model.load_state_dict(th.load(root_folder+'bert_models/teacher_mrpc.pt'))\n",
    "student_model = BertForNextSentencePrediction(student_config).to(device)\n",
    "student_model.load_state_dict(th.load(root_folder+'bert_models/student_wikitext.pt'),strict=False)\n",
    "criterion = KnowledgeDistillationLoss(teacher_embd_dim,student_embd_dim,teacher_hddn_dim,student_hddn_dim,layer_mapping).to(device)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M4qnKJsRsA3w"
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "gc.collect()\n",
    "optimizer = optim.Adam(params=student_model.parameters(),lr=5e-5,weight_decay=0.01)\n",
    "student_model.to(device)\n",
    "lr = 1e-4\n",
    "batch_size = 10\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    mrpc[\"train\"].shuffle(load_from_cache_file=False)\n",
    "    t = tqdm(range(0,len(mrpc[\"train\"]),batch_size))\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i in t:\n",
    "        data = mrpc[\"train\"][i:i+batch_size]\n",
    "        data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "        teacher_out = teacher_model(**data,**forward_kwargs)\n",
    "        student_out = student_model(**data,**forward_kwargs)\n",
    "        teacher_out['embeddings'] = teacher_model.get_input_embeddings().weight\n",
    "        student_out['embeddings'] = student_model.get_input_embeddings().weight\n",
    "        loss = criterion(teacher_out,student_out,penalize_prediction=True)\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accuracy = th.eq(student_out['logits'].argmax(dim=1,keepdim=False).float(),data['labels']).float().mean()\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        loss = np.around(np.mean(losses[-100:]),3)\n",
    "        accuracy = np.around(np.mean(accuracies[-100:]),2)\n",
    "        t.set_description(\"Epoch: \"+str(epoch)+\" Loss: \"+str(loss)+\" Accuracy: \"+str(accuracy))\n",
    "    os.makedirs(root_folder+'bert_models',exist_ok=True)\n",
    "    th.save(student_model.state_dict(),root_folder+'bert_models/student_mrpc.pt')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdYyORtusA30"
   },
   "source": [
    "We next train a control, which is just the same BERT shaped student model trained from scratch on general and task specific data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PeOX276S-p9f"
   },
   "source": [
    "control_model = BertForNextSentencePrediction(student_config).to(device)\n",
    "control.load_state_dict(th.load(root_folder+'bert_models/control_wikitext.pt'),strict=False)\n",
    "gc.collect()\n",
    "control_model.train()\n",
    "optimizer = optim.Adam(params=student_model.parameters(),lr=lr,weight_decay=0.01)\n",
    "lr = 1e-4\n",
    "batch_size = 10\n",
    "epochs=1\n",
    "for epoch in range(epochs):\n",
    "    mrpc[\"train\"].shuffle()\n",
    "    t = tqdm(range(0,len(mrpc[\"train\"]),batch_size))\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i in t:\n",
    "        data = mrpc[\"train\"][i:i+batch_size]\n",
    "        data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "        student_out = student_model(**data,**forward_kwargs)\n",
    "        losses.append(student_out['loss'].detach().cpu().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        student_out['loss'].backward()\n",
    "        optimizer.step()\n",
    "        accuracy = th.eq(student_out['logits'].argmax(dim=2,keepdim=False).float(),data['labels']).float().mean()\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        loss = np.around(np.mean(losses[-100:]),3)\n",
    "        accuracy = np.around(np.mean(accuracies[-100:]),2)\n",
    "        t.set_description(\"Epoch: \"+str(epoch)+\" Loss: \"+str(loss))\n",
    "    os.makedirs(root_folder+'bert_models',exist_ok=True)\n",
    "    th.save(control_model.state_dict(),root_folder+'bert_models/control_wikitext.pt')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0osHIcMCbFu"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJlXrT73Cjgn"
   },
   "source": [
    "##BERT Wikitext Specific Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kSfBjx6eCPCr"
   },
   "source": [
    "%%capture\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "tokenized_datasets = datasets.map(lambda samples: tokenizer(samples['text']), batched=True, num_proc=4, remove_columns=[\"text\"])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaKg2I6xCPCs"
   },
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_qaFbanmCPCt"
   },
   "source": [
    "%%capture\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=False\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LwOUQXDLCPCz"
   },
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import gc\n",
    "gc.collect()\n",
    "teacher_model.train()\n",
    "optimizer = optim.Adam(params=teacher_model.parameters(),lr=lr,weight_decay=0.01)\n",
    "lr = 1e-4\n",
    "batch_size = 10\n",
    "epochs=1\n",
    "for epoch in range(epochs):\n",
    "    lm_datasets[\"train\"].shuffle()\n",
    "    t = tqdm(range(0,len(lm_datasets[\"train\"]),batch_size))\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i in t:\n",
    "        data = lm_datasets[\"train\"][i:i+batch_size]\n",
    "        data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "        teacher_out = teacher_model(**data,**forward_kwargs)\n",
    "        losses.append(teacher_out['loss'].detach().cpu().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        teacher_out['loss'].backward()\n",
    "        optimizer.step()\n",
    "        accuracy = th.eq(teacher_out['logits'].argmax(dim=2,keepdim=False).float(),data['labels']).float().mean()\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        loss = np.around(np.mean(losses[-100:]),3)\n",
    "        accuracy = np.around(np.mean(accuracies[-100:]),2)\n",
    "        t.set_description(\"Epoch: \"+str(epoch)+\" Loss: \"+str(loss)+\" Accuracy: \"+str(accuracy))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ljmtYeeoCPC0"
   },
   "source": [
    "teacher_model.eval()\n",
    "lm_datasets[\"validation\"].shuffle()\n",
    "t = tqdm(range(0,len(lm_datasets[\"validation\"]),batch_size))\n",
    "for i in t:\n",
    "    data = lm_datasets[\"validation\"][i:i+batch_size]\n",
    "    data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "    teacher_out = teacher_model(**data,**forward_kwargs)\n",
    "    losses.append(teacher_out['loss'].detach().cpu().numpy())\n",
    "    \n",
    "    accuracy = th.eq(teacher_out['logits'].argmax(dim=2,keepdim=False).float(),data['labels']).float().mean()\n",
    "    accuracies.append(accuracy.detach().cpu().numpy())\n",
    "    loss = np.around(np.mean(losses),3)\n",
    "    accuracy = np.around(np.mean(accuracies),2)\n",
    "    t.set_description(\"Validation - \"+\"Loss: \"+str(loss)+\" Accuracy: \"+str(accuracy))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E5EBMMfBCPC1"
   },
   "source": [
    "os.makedirs(root_folder+'bert_models',exist_ok=True)\n",
    "th.save(teacher_model.state_dict(),root_folder+'bert_models/teacher_wikitext.pt')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4wghDKGvWRm"
   },
   "source": [
    "##BERT MRPC Specific Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iJstjDEivWw8"
   },
   "source": [
    "%%capture\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset('glue', 'mrpc')\n",
    "mrpc_tok = datasets.map(lambda samples: tokenizer(samples['sentence1'], samples['sentence2'],padding='max_length',max_length=150),\n",
    "                       remove_columns=['sentence1', 'sentence2','idx'],\n",
    "                       load_from_cache_file=False,\n",
    "                      )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XH2GqNSXvWw9"
   },
   "source": [
    "%%capture\n",
    "def filter_texts(examples):\n",
    "    examples[\"labels\"] = examples[\"label\"].copy()\n",
    "    examples.pop('label',None)\n",
    "    return examples\n",
    "mrpc = mrpc_tok.map(\n",
    "    filter_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=False\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PnGTEIORvWw_"
   },
   "source": [
    "%%capture\n",
    "from transformers import BertForNextSentencePrediction, BertForSequenceClassification\n",
    "teacher_model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\").to(device)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YiwILDOpv1pH"
   },
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import gc\n",
    "gc.collect()\n",
    "teacher_model.train()\n",
    "lr = 2e-5\n",
    "batch_size = 10\n",
    "epochs=10\n",
    "optimizer = optim.Adam(params=teacher_model.parameters(),lr=lr,weight_decay=0.01)\n",
    "for epoch in range(epochs):\n",
    "    mrpc[\"train\"].shuffle(load_from_cache_file=False)\n",
    "    t = tqdm(range(0,len(mrpc[\"train\"]),batch_size))\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i in t:\n",
    "        data = mrpc[\"train\"][i:i+batch_size]\n",
    "        data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "        teacher_out = teacher_model(**data,**forward_kwargs)\n",
    "        losses.append(teacher_out['loss'].detach().cpu().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        teacher_out['loss'].backward()\n",
    "        optimizer.step()\n",
    "        accuracy = th.eq(teacher_out['logits'].argmax(dim=1,keepdim=False).float(),data['labels']).float().mean()\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        loss = np.around(np.mean(losses[-100:]),3)\n",
    "        accuracy = np.around(np.mean(accuracies[-100:]),2)\n",
    "        t.set_description(\"Epoch: \"+str(epoch)+\" Loss: \"+str(loss)+\" Accuracy: \"+str(accuracy))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VGBVGfo7v1pJ"
   },
   "source": [
    "teacher_model.eval()\n",
    "mrpc[\"validation\"]\n",
    "t = tqdm(range(0,len(mrpc[\"validation\"]),batch_size))\n",
    "for i in t:\n",
    "    data = mrpc[\"validation\"][i:i+batch_size]\n",
    "    data = {k: th.tensor(v).to(device) for k,v in data.items()}\n",
    "    teacher_out = teacher_model(**data,**forward_kwargs)\n",
    "    losses.append(teacher_out['loss'].detach().cpu().numpy())\n",
    "    \n",
    "    accuracy = th.eq(teacher_out['logits'].argmax(dim=1,keepdim=False).float(),data['labels']).float().mean()\n",
    "    accuracies.append(accuracy.detach().cpu().numpy())\n",
    "    loss = np.around(np.mean(losses),3)\n",
    "    accuracy = np.around(np.mean(accuracies),2)\n",
    "    t.set_description(\"Validation - \"+\"Loss: \"+str(loss)+\" Accuracy: \"+str(accuracy))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iuenOJXTv1pL"
   },
   "source": [
    "os.makedirs(root_folder+'bert_models',exist_ok=True)\n",
    "th.save(teacher_model.state_dict(),root_folder+'bert_models/teacher_mrpc.pt')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}